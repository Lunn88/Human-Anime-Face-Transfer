{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from io import BytesIO\n",
    "\n",
    "import base64\n",
    "import requests\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils as vutils\n",
    "from cartoonize_network.Transformer import Transformer\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Transformer()\n",
    "model.eval()\n",
    "model.load_state_dict(torch.load(\"./cartoonize_pretrained_models/Hosoda_net_G_float.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform(model, input_image):\n",
    "    model.cuda()\n",
    "\n",
    "    h, w = input_image.size\n",
    "\n",
    "    input_image = input_image.resize((h, w), Image.BICUBIC)\n",
    "    input_image = np.asarray(input_image)\n",
    "\n",
    "    input_image = input_image[:, :, [2, 1, 0]]\n",
    "    input_image = transforms.ToTensor()(input_image).unsqueeze(0)\n",
    "\n",
    "    input_image = -1 + 2 * input_image\n",
    "    input_image = Variable(input_image).cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_image = model(input_image)[0]\n",
    "\n",
    "    output_image = output_image[[2, 1, 0], :, :]\n",
    "    output_image = output_image.data.cpu().float() * 0.5 + 0.5\n",
    "\n",
    "    output_image = output_image.numpy()\n",
    "\n",
    "    output_image = np.uint8(output_image.transpose(1, 2, 0) * 255)\n",
    "    output_image = Image.fromarray(output_image)\n",
    "\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|███████████████████████████████████████████████████████████| 5000/5000 [09:48<00:00,  9.20it/s]\n"
     ]
    }
   ],
   "source": [
    "ffhq_folder_path = \"./uncartoonized\"\n",
    "cartoonized_folder_path = \"./cartoonized\"\n",
    "\n",
    "for file in tqdm(os.listdir(ffhq_folder_path), desc=\"Processing images\"):\n",
    "    if file.endswith(\".png\"):\n",
    "        image_path = os.path.join(ffhq_folder_path, file)\n",
    "        with Image.open(image_path) as img:\n",
    "            output = transform(model, img)\n",
    "            output_path = os.path.join(cartoonized_folder_path, file)  # 保留原始圖片名稱\n",
    "            output.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
